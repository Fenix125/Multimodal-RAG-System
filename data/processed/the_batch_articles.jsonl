{"article_id":"inside-olmo-3-a-new-family-of-fully-open-models","title":"Inside Olmo 3, a new family of fully open models: Grok 4.1’s uneasy balance between EQ and sycophancy","url":"https://www.deeplearning.ai/the-batch/inside-olmo-3-a-new-family-of-fully-open-models/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-11-24T11:47:00-08:00","body_text":"Welcome back! In today’s edition of Data Points, you’ll learn more about:\nNano Banana Pro, Google’s updated image generator\nAnthropic’s latest partnerships with Microsoft and Nvidia\nMemo, a home robot trained on real-life human tasks\nA new AI play modeled on legendary French playwright Molière’s work\nBut first:\nOlmo 3 opens complete development pipeline to researchers\nThe Allen Institute for AI released Olmo 3, a family of open-source language models that exposes the entire “model flow”: every training stage, checkpoint, dataset, and dependency required to create and modify the models. The release includes Olmo 3-Base (7 billion and 32 billion parameters), Olmo 3-Think (the strongest fully open 32 billion-parameter reasoning model), Olmo 3-Instruct (for chat and tool use), and Olmo 3-RL Zero (for reinforcement learning experiments). Olmo 3-Base outperforms other fully open base models on benchmarks for programming, reading comprehension, and math, while Olmo 3-Think narrows the gap with leading open-weight models like Qwen 3 despite training on roughly six times fewer tokens. The release enables researchers to trace model behaviors back to specific training data and decisions, fork development at any stage, and conduct experiments that require full visibility into how AI systems learn, all of which help address concerns about transparency and accountability in AI development. All components, including the 9.3 trillion-token Dolma 3 training corpus and post-training datasets, are available under permissive open-source licenses. (\nAllen AI\n)\nxAI’s Grok 4.1 tops emotional intelligence leaderboard\nGrok 4.1 now leads EQ-Bench3, a benchmark that measures how well language models handle emotional intelligence through roleplay scenarios. The model beat GPT-4o and Claude 3.5 Sonnet on metrics like empathy and interpersonal skills, but it also became more overly agreeable and flattering, even when it’s wrong. This trade-off between emotional warmth and truthfulness is a challenge that all major AI labs are dealing with as they tune their models. For developers building customer support, coaching, or wellness apps, this means picking a high-EQ model now requires weighing the benefits against the risk of a system that prioritizes agreeableness over accuracy. The benchmark itself relies on another AI to judge responses, which raises questions about whether models are developing real emotional intelligence or just learning to please other AI systems. (\nxAI\n and \ni10x.ai\n)\nGemini’s latest image generator has landed\nGoogle released Nano Banana Pro, an image generation model built on Gemini 3 Pro that creates detailed visuals with accurate text rendering in multiple languages. The model can generate educational infographics, translate text within images, and combine up to 14 input images while keeping up to five people looking consistent across compositions. It also offers professional controls like adjustable lighting, camera angles, and color grading, with output available in resolutions up to 4K. The model is rolling out across Google products including the Gemini app (with limited free quotas), Google Ads, Workspace tools, and developer platforms like Vertex AI. All generated images include Google’s SynthID watermark for verification. (\nGoogle\n)\nAnthropic’s valuation soars with new cloud partnerships\nMicrosoft and Nvidia announced investments of up to $5 billion and $10 billion respectively in Anthropic on Tuesday, pushing the AI startup’s valuation to around $350 billion, up from $183 billion in September. Anthropic committed to purchasing $30 billion of Azure compute capacity from Microsoft and up to 1 gigawatt of compute capacity from Nvidia, while Nvidia will collaborate with Anthropic on engineering and design to optimize Claude models for its architectures. The partnerships mark a strategic shift for Microsoft; backing Anthropic reduces its dependence on OpenAI (where it holds a roughly 27 percent stake valued at $135 billion). The deals reshapes the competitive landscape for AI developers, with Anthropic now simultaneously backed by Microsoft, Nvidia, Google, and Amazon, cementing Claude’s developer as a central player with the industry’s major cloud providers and chip makers. (\nMicrosoft\n and \nCNBC\n)\nSunday unveils Memo, a home robot trained on millions of tasks\nSunday Robotics emerged from stealth with Memo, a wheeled home robot designed to handle chores like dishes, laundry, and tidying. The company trained Memo using roughly 10 million recordings of household routines collected from over 500 homes, where workers wore Sunday’s Skill Capture Glove, a $400 wearable that captures human movements more accurately than standard remote control methods. Memo can make espresso, clear tables, and load dishwashers. However, it works slowly and the real test will be how well it performs in actual homes without engineers present. The approach tackles a key problem in robotics: most home robots fail because they’re trained in labs rather than messy, unpredictable real-world environments. Sunday will accept applications for a beta program starting November 19, 2025, with 50 households receiving numbered robots in late 2026. (\nSunday\n and \nWired\n)\nAI-generated Molière play to debut at Palace of Versailles\nFrench scholars, artists, and AI firm Mistral collaborated to create “L’Astrologue ou les Faux Presages” (The Astrologer or the False Omens), a comedy imagining what 17th-century playwright Molière might have written next had he not died at age 51. The AI model analyzed Molière’s complete works to generate a play satirizing astrologers, centering on a gullible bourgeois deceived by a fraudulent fortune-teller. Researchers and scholars corrected historical inaccuracies and refined the AI’s output throughout the production process. The project suggests how AI can help scholars gain new insights into classic literature by identifying patterns scattered across an author’s body of work. The play will premiere in 2026 at the Palace of Versailles, where Molière’s patron Louis XIV once held court. (\nReuters\n)\nA special offer for our community\nDeepLearning.AI recently launched the first-ever subscription plan for our entire course catalog! As a Pro Member, you’ll immediately enjoy access to:\nOver 150 AI courses and specializations from Andrew Ng and industry experts\nLabs and quizzes to test your knowledge\nProjects to share with employers\nCertificates to testify to your new skills\nA community to help you advance at the speed of AI\nEnroll now to lock in a year of full access for $25 per month paid upfront, or opt for month-to-month payments at just $30 per month. Both payment options begin with a one week free trial. Explore Pro’s benefits and start building today!\nTry Pro Membership\nWant to know more about what matters in AI right now?\nRead \nthe latest issue\n of \nThe Batch\n for in-depth analysis of news and research.\nLast week, Andrew Ng talked about the AI Dev x NYC conference, highlighted the optimism in the AI community despite broader skepticism, and emphasized the importance of in-person events for sparking new opportunities and collaborations.\n“Speaking with fellow developers, I realized that because of AI’s low penetration in businesses, it is simultaneously true that (a) many businesses do not yet have AI delivering significant ROI, and (b) many skilled AI teams are starting to deliver significant ROI and see the number of successful AI projects climbing rapidly, albeit from a low base. This is why AI developers are bullish about the growth that is to come!”\nRead Andrew’s letter \nhere\n.\nOther top AI news and research stories we covered in depth:\nWaymo deployed \nself-driving cars on expressways in California and Arizona\n, marking an important step in integrating autonomous vehicles on U.S. freeways.\nKimi K2 Thinking \noutperformed proprietary models with new techniques for agentic tool use\n, showing leading results with open weights.\nA recent \nAnthropic cyberattack report sparked controversy\n, as security researchers questioned the potential for unprecedented automated attacks carried out by coding agents.\nResearchers developed \nmore efficient agentic search\n by fine-tuning models to search within their own parameters, which significantly improved recall.\nSubscribe to Data Points","images":[{"image_id":"inside-olmo-3-a-new-family-of-fully-open-models_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/11/Whisk_74995b1922fce2b9f524912f09cb01d7eg.png","local_path":null,"alt":"Technicians monitor holographic ballet dancers on stage via futuristic screens and robotic controls in a theater setting."}]}
{"article_id":"meta-model-detects-and-segments-video-objects","title":"Meta model detects and segments video objects: Google Gemini 3 wows on benchmark tests and leaderboards","url":"https://www.deeplearning.ai/the-batch/meta-model-detects-and-segments-video-objects/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-11-21T12:05:00-08:00","body_text":"In today’s edition of Data Points, you’ll learn more about:\nGPT-5.1-Codex-Max, OpenAI’s improved long-context coding model\nMusic startup Klay’s reported deal with Universal, Warner, and Sony\nDeepSeek R1 Slim, a trim, decensored reasoning model\nNTT’s Tsuzumi 2, an efficient model optimized for Japan\nBut first:\nMeta’s SAM 3 adds text prompts and video tracking\nMeta released Segment Anything Model 3 (SAM 3), a unified AI model that detects, segments, and tracks objects in images and videos using text, exemplar, and visual prompts. The model accepts open-vocabulary text prompts like “striped red umbrella” rather than fixed label sets, and delivers a 2x performance gain over existing systems on Meta’s new SA-Co benchmark. Meta built SAM 3 using a hybrid data engine combining human annotators with AI models, including Llama-based systems, which annotated data 5x faster than humans alone and created a training set with over 4 million unique concepts. SAM 3 enables new features across Meta’s products, including object-specific effects in Instagram’s Edits app and a View in Room feature for Facebook Marketplace. Meta released model weights, fine-tuning code, evaluation datasets, and the Segment Anything Playground platform for public experimentation. (\nMeta\n)\nGoogle releases Gemini 3, claiming top spot on AI leaderboards\nGoogle launched Gemini 3, its newest multimodal model, which scored 1,501 Elo on the LMArena Leaderboard and topped the WebDev Arena with 1,487 Elo. The model achieved 91.9 percent on GPQA Diamond, 81 percent on MMMU-Pro, and 76.2 percent on SWE-bench Verified, demonstrating advances in reasoning, multimodal understanding, and coding capabilities. Google previewed Gemini 3 Deep Think, an enhanced reasoning mode that scored 93.8 percent on GPQA Diamond and 45.1 percent on ARC-AGI-2. The company also introduced Google Antigravity, an agentic development platform that enables autonomous planning and execution of complex software tasks. Gemini 3 is now available in the Gemini app, AI Studio, Vertex AI, and third-party platforms like Cursor and GitHub. Gemini 3 Deep Think will roll out to Google AI Ultra subscribers in the coming weeks following additional safety testing. (\nGoogle\n)\nOpenAI released GPT-5.1-Codex-Max, a coding model designed for long-running tasks\nGPT-5.1-Codex-Max uses 30 percent fewer thinking tokens than its predecessor while achieving better performance on benchmarks like SWE-bench Verified, and can work independently for more than 24 hours on complex tasks. The model is OpenAI’s first to be natively trained to operate across multiple context windows through a process called “compaction,” enabling it to work coherently over millions of tokens in a single task for project-scale refactors, debugging sessions, and multi-hour agent loops. OpenAI noted that it is their most capable cybersecurity model to date and implemented additional safeguards to prevent misuse. GPT-5.1-Codex-Max is available now in Codex for ChatGPT Plus, Pro, Business, Edu, and Enterprise plans, with API access coming soon. (\nOpenAI\n)\nKlay becomes first AI company to license music from all three major labels\nKlay secured licensing agreements with Universal Music Group, Sony Music, and Warner Music Group to build a streaming service that lets users remake songs with AI tools, \nBloomberg\n reported. The startup licensed thousands of hit songs to train its large language model and promised artists and labels control over how their work is used. Klay is led by music producer Ary Attie and employs former executives from Sony Music and Google’s DeepMind. The deals mark a shift in the music industry’s approach to AI, as labels try to embrace the technology while protecting their copyrights amid ongoing lawsuits against other AI music companies like Suno. (\nBloomberg\n)\nSpanish quantum physicists claim to have removed censorship from DeepSeek R1\nResearchers at Multiverse Computing created DeepSeek R1 Slim, a version of the Chinese reasoning model that is 55 percent smaller and allegedly free of government-imposed censorship. The team used tensor networks — a mathematical technique borrowed from quantum physics — to compress the model while selectively removing specific information, including censorship filters required by Chinese regulations. They tested the modified model on approximately 25 politically sensitive questions, such as references to President Xi Jinping and the Tiananmen Square protests, and used GPT-5 to evaluate whether responses matched Western models’ factual output. The work reflects broader industry efforts to make AI models more efficient and raises questions about how censorship embedded in Chinese open-source models shapes the global AI ecosystem. But experts warn that fully removing censorship from models trained on restricted data may be more complex than a small test set can verify. (\nMIT Technology Review\n and \nMultiverse Computing\n)\nNTT’s lightweight model challenges the need for massive GPU infrastructure\nNTT launched Tsuzumi 2, a large language model that runs on a single GPU instead of the dozens or hundreds that most enterprise AI systems require. In internal tests for financial-system inquiries, the model performed as well as much larger systems while using a fraction of the computing resources. Tokyo Online University deployed it on-premise to handle course Q&A, create teaching materials, and provide student guidance—keeping sensitive data on campus while avoiding the cost of building GPU clusters. The model works particularly well with Japanese text and includes specialized knowledge in finance, medicine, and public sector applications, allowing organizations to deploy it without extensive customization. For enterprises concerned about sending proprietary data to cloud-based AI services, localized models like Tsuzumi 2 offer an alternative: run the model locally, process sensitive information internally, and handle text, images, and voice without managing multiple specialized systems. (\nNTT\n)\nA special offer for our community\nDeepLearning.AI recently launched the first-ever subscription plan for our entire course catalog! As a Pro Member, you’ll immediately enjoy access to:\nOver 150 AI courses and specializations from Andrew Ng and industry experts\nLabs and quizzes to test your knowledge \nProjects to share with employers \nCertificates to testify to your new skills\nA community to help you advance at the speed of AI\nEnroll now to lock in a year of full access for $25 per month paid upfront, or opt for month-to-month payments at just $30 per month. Both payment options begin with a one week free trial. Explore Pro’s benefits and start building today!\nTry Pro Membership\nStill want to know more about what matters in AI right now?\nRead \nthis week’s issue\n of The Batch for in-depth analysis of news and research.\nThis week, Andrew Ng talked about the \nAI Dev x NYC conference,\n highlighting the optimism in the AI community despite broader skepticism, and emphasized the importance of in-person events for sparking new opportunities and collaborations.\n“The event was full of conversations about coding with AI, agentic AI, context engineering, governance, and building and scaling AI applications in startups and in large corporations. But the overriding impression I took away was one of near-universal optimism about our field, despite the mix of pessimism and optimism about AI in the broader world.”\nRead Andrew’s full letter \nhere\n.\nOther top AI news and research stories we covered in depth:\nWaymo deployed \nself-driving cars on expressways in California and Arizona\n, marking an important step in integrating autonomous vehicles on U.S. freeways.\nKimi K2 Thinking \noutperformed proprietary models with new techniques for agentic tool use\n, showing leading results with open weights.\nA recent \nAnthropic cyberattack report sparked controversy\n, as security researchers questioned the potential for unprecedented automated attacks carried out by coding agents.\nResearchers developed \nmore efficient agentic search\n by fine-tuning models to search within their own parameters, which significantly improved recall.\nSubscribe to Data Points","images":[{"image_id":"meta-model-detects-and-segments-video-objects_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/11/Japanese-computer-scientists-pointing-at-a-screen.png","local_path":null,"alt":"Japanese computer scientists pointing at a screen"}]}
{"article_id":"openai-looks-inside-neural-networks","title":"OpenAI looks inside neural networks: Baidu’s multimodal ERNIE 5.0 arrives, priced to compete","url":"https://www.deeplearning.ai/the-batch/openai-looks-inside-neural-networks/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-11-17T08:37:00-08:00","body_text":"Welcome back! In today’s edition of Data Points, you’ll learn more about:\nVibeThinker-1.5B, a small but powerful reasoning model\nToymakers’ recall of AI dolls that tell kids how to start fires\nQwen3-Max’s discounts and the latest AI price war\nSIMA 2, Google’s self-learning game-playing model\nBut first:\nOpenAI trained sparse neural networks to better interpret them\nAn interpretability team at OpenAI developed a new training method that forces language models to use far fewer connections between neurons, creating simpler networks that researchers can more easily understand. The team trained models similar to GPT-2 but constrained most weights to zero, limiting each neuron to only a few dozen connections instead of thousands. For simple tasks, researchers successfully isolated minimal “circuits” of neurons that perform specific, traceable operations — like a five-channel circuit that matches Python quote types by detecting, classifying, and copying the correct quote. This mechanistic interpretability approach could provide a path to reverse-engineer AI behavior, though significant challenges remain to scale the technique to larger, frontier models. (\nOpenAI\n)\nBaidu launches ERNIE 5.0 to compete with GPT-5 and Gemini 2.5 Pro\nChinese search giant Baidu unveiled ERNIE 5.0, a proprietary model that processes and generates content across text, images, audio, and video. The model is available through Baidu’s ERNIE Bot website and Qianfan cloud platform API. It’s less expensive than GPT-5.1 and Gemini 2.5 Pro, priced at $0.85 per million input tokens and $3.40 per million output tokens. According to Baidu’s internal benchmarks, ERNIE 5.0 matched or beat GPT-5 and Gemini 2.5 Pro in multimodal reasoning, document understanding, and image-based question answering. The company showed particularly strong performance on structured document and chart analysis. Independent verification of Baidu’s performance claims is pending. (\nVentureBeat\n)\nVibeThinker-1.5B matches much larger models for just $7,800\nWeibo released VibeThinker-1.5B, a 1.5 billion parameter language model that matches or exceeds the mathematical reasoning of models with hundreds of times more parameters. On three major math benchmarks (AIME24, AIME25, and HMMT25), the model scored 80.3, 74.4, and 50.4 respectively. These scores surpass DeepSeek-R1 despite that model having 400 times more parameters. The model also achieved competitive code generation scores of 55.9 on LiveCodeBench v5 and 51.1 on v6. VibeThinker-1.5B uses a training framework that first explores solution diversity during supervised fine-tuning, then optimizes correct signals through reinforcement learning. The model is available under an MIT license. (\nHugging Face\n)\nAI-powered toys fail safety tests, give kids dangerous advice\nConsumer advocacy group PIRG tested four AI-enabled toys and found that none met basic safety standards for children. The worst performer, a teddy bear called Kumma from Chinese company FoloToy, provided detailed instructions on using matches and knives, discussed sexual kinks unprompted, and explained “teacher-student roleplay” involving spanking. The toys also raised serious privacy concerns, with constant listening, biometric data storage for up to three years, and voice recordings processed by third parties. PIRG’s researchers found that despite OpenAI’s policy against children using ChatGPT, several toys use GPT-4o as their default model and lack parental controls or usage limits. FoloToy has suspended sales of Kumma and launched an internal safety audit in response to the findings. (\nThe Register\n)\nAlibaba cuts prices for Qwen3-Max AI model by nearly half\nAlibaba Cloud reduced pricing for its Qwen3-Max model by almost 50 percent, lowering the minimum cost to $0.459 per million input tokens and $1.836 per million output tokens. The trillion-parameter model, launched in September as one of Alibaba’s most expensive offerings, now includes an additional 50 percent discount for batch API calls during non-peak hours. The price cuts follow recent model releases from Chinese AI startups like Moonshot AI, Zhipu AI, and MiniMax, each emphasizing performance and cost efficiency. The move reflects fierce competition in China’s AI market, which has experienced multiple price wars in recent years, including battles over coding models and foundational AI systems. (\nSouth China Morning Post\n)\nGoogle DeepMind’s SIMA 2 learns to play video games on its own\nGoogle’s new SIMA 2 agent can play video games, follow instructions, and learn through self-directed play. The system uses Gemini’s reasoning capabilities to understand goals and execute multi-step tasks across diverse 3D gaming environments. SIMA 2 can interpret sketches, emojis, and multiple languages, and it improves its performance through trial-and-error without human help. The research could eventually be applied to general embodied intelligence with potential applications in robotics. Google is releasing SIMA 2 as a limited research preview to academics and game developers. (\nGoogle\n)\nA special offer for our community\nDeepLearning.AI recently launched the first-ever subscription plan for our entire course catalog! As a Pro Member, you’ll immediately enjoy access to:\nOver 150 AI courses and specializations from Andrew Ng and industry experts\nLabs and quizzes to test your knowledge\nProjects to share with employers\nCertificates to testify to your new skills\nA community to help you advance at the speed of AI\nEnroll now to lock in a year of full access for $25 per month paid upfront, or opt for month-to-month payments at just $30 per month. Both payment options begin with a one week free trial. Explore Pro’s benefits and start building today!\nTry Pro Membership\nWant to know more about what matters in AI right now?\nRead \nthe latest issue\n of \nThe Batch\n for in-depth analysis of news and research.\nLast week, Andrew Ng talked about the misconceptions surrounding AI’s capabilities, emphasizing that while AI was impressive, it still had significant limitations and required customization for specific tasks.\n“AI is amazing, but it has unfortunately been hyped up to be even more amazing than it is. A pernicious aspect of hype is that it often contains an element of truth, but not to the degree of the hype. This makes it difficult for nontechnical people to discern where the truth really is. Modern AI is a general purpose technology that is enabling many applications, but AI that can do any intellectual tasks that a human can (a popular definition for AGI) is still decades away or longer.”\nRead Andrew’s letter \nhere\n.\nOther AI news and research stories we covered that might scare you to your bones:\nCharacter AI and OpenAI implemented \npolicy changes to protect younger and vulnerable users\n, aiming for safer and more responsible chatbot interactions.\nHunyuanImage-3.0 improved image generation by \nusing reinforcement learning and thinking tokens\n to better interpret and respond to prompts.\nThe State of AI Report 2025 highlighted that \nAI’s barriers were not technological but social and material\n, marking a pivotal year for AI’s industrial adoption.\nAmazon’s Chronos-2 advanced forecasting by \nsorting out tangled variables to make better predictions\n across multiple time series.\nSubscribe to Data Points","images":[{"image_id":"openai-looks-inside-neural-networks_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/11/Interpretability-scientists-studying-map-of-neural-network.png","local_path":null,"alt":"A large screen showing a conceptual map of a sparse neural network, surrounded by a team of computer scientists"}]}
{"article_id":"generating-persistent-editable-3d-worlds","title":"Generating persistent, editable 3D worlds: Exploring the limits of small synthetic datasets","url":"https://www.deeplearning.ai/the-batch/generating-persistent-editable-3d-worlds/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-11-14T12:08:00-08:00","body_text":"In today’s edition of Data Points, you’ll learn more about:\nOpenAI’s GPT-5.1, a more personalizable agentic model\nProject FETCH’s use of Claude to program robots\nBaidu’s new VL model that tops Gemini Pro and GPT-5\nOpenAI liable for copyrighted song lyrics\nBut first:\nWorld Labs debuts Marble, a 3D world generator with editing tools\nThe AI startup founded by Fei-Fei Li launched its first commercially available generative world model that converts text prompts, photos, videos, 3D layouts, or panoramas into editable, downloadable 3D environments. Unlike competitors like Decart, Odyssey, and Google’s Genie, Marble creates persistent 3D spaces that users can export as Gaussian splats, meshes, or videos, rather than generating worlds on-the-fly. The model includes AI-native editing tools and a hybrid 3D editor called Chisel that lets users block out structures in space before AI fills in the details, giving developers more control over generated environments. The model can be used in gaming, visual effects for film, and virtual reality, with developers able to export assets into game engines like Unity or Unreal Engine. Marble offers four subscription tiers ranging from free (four generations) to $95 per month (75 generations with all features and commercial rights). (\nTechCrunch\n)\nHow SYNTH trains small AI models with 50 times less data\nFrench researchers released a synthetic dataset built from 50,000 Wikipedia articles that trains language models specifically for reasoning rather than using general web text. The dataset includes diverse problem types, from math exercises to creative writing, with structured reasoning traces that help models learn more efficiently than traditional pretraining approaches. Using SYNTH, the team trained two small models on fewer than 200 billion tokens: Baguettotron (321 million parameters) achieved state-of-the-art results in its class on major benchmarks including MMLU and gsm8k, while Monad (56 million parameters) became what researchers claim is the smallest viable language model. The project required only 1,000 H100 hours for final training runs, demonstrating that synthetic data focused on reasoning can produce competitive models at dramatically lower computational costs than conventional approaches. SYNTH is released under open licenses, with all synthetic outputs traced back to verifiable Wikipedia sources. (\nPleias\n)\nOpenAI updates GPT-5 in ChatGPT and the API\nOpenAI released GPT-5.1, a new model that dynamically adjusts its reasoning time based on task complexity. The model includes a “no reasoning” mode for faster responses on simple tasks, extended prompt caching for up to 24 hours, and two new tools: apply_patch for more reliable code editing and a shell tool for running command-line operations. Early testing showed GPT-5.1 runs 2-3 times faster than GPT-5 on everyday tasks while using about half as many tokens, and it achieved 76.3 percent accuracy on SWE-bench Verified, outperforming GPT-5’s 72.8 percent. The model is available to all paid API users at the same pricing as GPT-5, with specialized variants gpt-5.1-codex and gpt-5.1-codex-mini optimized for long-running coding tasks. (\nOpenAI\n)\nAnthropic “Project Fetch” shows Claude halves non-experts’ time to program unfamiliar robotics tasks\nAnthropic divided eight of its researchers into two teams (one with Claude access, one without) and asked them to program robotic dogs to fetch beach balls. Team Claude accomplished more tasks and completed them in about half the time, with only the AI-assisted team making substantial progress toward fully autonomous ball retrieval. Claude particularly excelled at helping teams connect to hardware and access sensor data. However, the AI-assisted team wrote roughly nine times more code. The study shows how AI models are beginning to bridge digital and physical worlds through robotics, suggesting that systems capable of independently interacting with previously unknown hardware may arrive soon. (\nAnthropic\n)\nBaidu unveils lightweight vision-language reasoning model\nBaidu released ERNIE-4.5-VL-28B-A3B-Thinking, a multimodal AI model that activates only 3 billion parameters while matching larger flagship models on various benchmarks. The model was trained using multimodal reinforcement learning techniques on visual-language reasoning data to improve alignment between vision and text. Key capabilities include chart analysis, STEM problem-solving from images, visual grounding with bounding box detection, and video understanding with temporal awareness. The model’s “Thinking with Images” feature enables it to autonomously zoom in on image regions and call external tools like image search to identify objects and retrieve information. The model is available with open weights under Apache License 2.0. (\nBaidu\n)\nGerman court rules OpenAI violated copyright law by training on song lyrics\nThe Munich court found that OpenAI infringed copyright by training its AI models on protected lyrics from nine German songs, including hits by best-selling musician Herbert Groenemeyer. The case was brought by GEMA, a German music rights society representing composers, lyricists, and publishers. OpenAI had argued that its language models don’t store specific training data and that users, not the company, should be liable for any copyrighted output generated through prompts, but the court rejected this defense. The ruling could set a precedent in Europe for how AI companies use copyrighted materials, adding to growing global pushback from artists against data scraping. (\nReuters\n)\nA special offer for our community \nDeepLearning.AI just launched the first-ever subscription plan for our entire course catalog! As a Pro Member, you’ll immediately enjoy access to:\nOver 150 AI courses and specializations from Andrew Ng and industry experts\nLabs and quizzes to test your knowledge \nProjects to share with employers \nCertificates to testify to your new skills\nA community to help you advance at the speed of AI\nEnroll now to lock in a year of full access for $25 per month paid upfront, or opt for month-to-month payments at just $30 per month. Both payment options begin with a one week free trial. Explore Pro’s benefits and start building today!\nTry Pro Membership\nStill want to know more about what matters in AI right now?\nRead \nthis week’s issue\n of The Batch for in-depth analysis of news and research.\nThis week, Andrew Ng discussed hype about AI’s capabilities, emphasizing that while AI is impressive, it still has significant limitations and requires customization for specific tasks.\n“Yes, AI is amazingly intelligent, and I’m thrilled to be using it every day to build things I couldn’t have built a year ago. At the same time, AI is still incredibly dumb, and I would not trust a frontier LLM by itself to prioritize my calendar, carry out resumé screening, or choose what to order for lunch — tasks that businesses routinely ask junior personnel to do.”\nRead Andrew’s full letter \nhere\n.\nOther top AI news and research stories we covered in depth:\nCharacter AI and OpenAI implemented \npolicy changes to protect younger and vulnerable users\n, aiming for safer and more responsible chatbot interactions.\nHunyuanImage-3.0 improved image generation by \nusing reinforcement learning and thinking tokens\n to better interpret and respond to prompts.\nThe State of AI Report 2025 highlighted that \nAI’s barriers were not technological but social and material\n, marking a pivotal year for AI’s industrial adoption.\nAmazon’s Chronos-2 advanced forecasting by \nsorting out tangled variables to make better predictions\n across multiple time series.\nSubscribe to Data Points","images":[{"image_id":"generating-persistent-editable-3d-worlds_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/11/Marble.png","local_path":null,"alt":"Blue glass sphere balancing on marble stairs."}]}
{"article_id":"meta-ai-now-recognizes-1600-languages","title":"Meta AI now recognizes 1600 languages: Amazon and Perplexity spar over browser agents","url":"https://www.deeplearning.ai/the-batch/meta-ai-now-recognizes-1600-languages/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-11-10T12:24:00-08:00","body_text":"In today’s edition of Data Points, you’ll learn more about:\nKimi K2 Thinking, the new top open model\nDeep Research’s expansion to personal documents\nTerminal-Bench makers’ new agentic benchmark\nTSMC’s slowing revenue growth\nBut first:\nOmnilingual ASR recognizes speech for over 1,600 languages\nMeta’s Fundamental AI Research team launched Omnilingual ASR, a suite of models that transcribes speech in more than 1,600 languages, including 500 low-resource languages never before transcribed by AI. The system uses a 7 billion parameter wav2vec 2.0 speech encoder paired with two decoder variants, achieving character error rates below 10 percent for 78 percent of supported languages. Users can extend the system to new languages using just a few audio-text sample pairs through in-context learning, eliminating the need for large training datasets or specialized expertise. The release offers a significant expansion in speech recognition accessibility, particularly for underrepresented language communities that have historically lacked high-quality transcription tools. Meta released all models under Apache 2.0 license, along with the Omnilingual ASR Corpus covering 350 underserved languages under CC-BY license. (\nMeta\n)\nAmazon sues Perplexity to block AI agent from making purchases\nAmazon filed a lawsuit against Perplexity AI to stop the startup’s Comet browser agent from making purchases on behalf of users on Amazon.com, accusing the company of computer fraud and violating its terms of service by disguising AI agents as real users. The e-commerce giant claims Perplexity continued deploying shopping bots even after being asked to stop in November 2024, and later circumvented Amazon’s security measures designed to block the agents. Perplexity CEO Aravind Srinivas defended the practice, arguing that AI agents should have “all the same rights and responsibilities” as human users and accused Amazon of bullying competitors while trying to protect its advertising business. The case could set important precedents for how far agentic AI systems can go in performing real-world tasks like shopping, as companies including Amazon, OpenAI, and Google race to develop their own AI agents. Disclosure: DeepLearning.AI’s Andrew Ng is a member of Amazon’s board of directors. (\nBloomberg/Yahoo\n)\nKimi K2 Thinking beats more costly models on agentic tasks\nMoonshot AI released Kimi K2 Thinking, a 1 trillion parameter reasoning model that currently ranks as the best open-source LLM and outperforms GPT-5 and Claude Sonnet 4.5 on several agentic benchmarks. The model scored 44.9 percent on Humanity’s Last Exam with tools enabled, beating GPT-5’s 41.7 percent, and achieved 60.2 percent on BrowseComp compared to GPT-5’s 54.9 percent by using an “interleaved thinking” approach that reasons between up to 300 tool calls. Moonshot trained the model for approximately $4.6 million using native INT4 quantization, which reduced the model size to 594GB and allowed it to run on less powerful hardware. Like DeepSeek-R1, K2 Thinking’s release challenges the notion that expensive proprietary model development remains necessary. The model is available under a modified MIT license that requires Kimi K2 branding for commercial services exceeding 100 million monthly active users or $20 million in monthly revenue. (\nHugging Face\n and \nCNBC\n)\nGemini Deep Research can access Gmail, Docs, Drive, and Chat\nGoogle expanded its Gemini Deep Research tool to pull information directly from users’ Gmail, Google Drive (including Docs, Slides, Sheets, and PDFs), and Google Chat alongside web sources. Users can now create comprehensive reports that combine internal company documents, email threads, and team chats with public web data—for example, analyzing competitor products using both proprietary strategy documents and external market information. The feature is available to all Gemini users on desktop through the Tools menu, with mobile access rolling out in the coming days. This integration addresses one of users’ most-requested features by allowing AI research to incorporate personal and organizational context rather than relying solely on public web information. (\nGoogle\n)\nTerminal-Bench 2.0 and Harbor now available for AI agent evaluation\nThe makers of Terminal-Bench released Harbor, a new framework that enables developers to evaluate and improve AI agents at scale using cloud-deployed containers. Harbor addresses common challenges in agent development by supporting horizontal scaling to thousands of containers, providing interfaces for supervised fine-tuning and reinforcement learning, and working with any agent that can be installed in a container. The release includes Terminal-Bench 2.0, a more difficult and better-verified version of the popular agent evaluation benchmark that launched in May 2024. The original Terminal-Bench became widely adopted by major AI labs and built a community of 1,000 Discord members and 100 GitHub contributors. Terminal-Bench 2.0 underwent extensive manual and language model-assisted verification to fix quality issues from version 1.0, such as tasks that broke due to changing website protections. (\nTerminal-Bench\n)\nTSMC reports slowest monthly revenue growth since February\nTaiwan Semiconductor Manufacturing Co. posted a 16.9 percent increase in October sales, its slowest monthly growth rate in eight months. The semiconductor manufacturer faces tight capacity constraints as major chip designers, including Nvidia and AMD, compete for production slots to meet surging AI chip demand. Despite the slower growth rate, industry executives remain optimistic about AI-driven expansion, with Meta, Alphabet, Amazon, and Microsoft planning to spend over $400 billion on AI infrastructure in 2026, a 21 percent increase from 2025. The news comes amid broader market concerns about a potential correction in AI and semiconductor stocks, following a recent slump in Asian technology shares. (\nBloomberg/Yahoo\n)\nA special offer for our community \nDeepLearning.AI just launched the first-ever subscription plan for our entire course catalog! As a Pro Member, you’ll immediately enjoy access to:\nOver 150 AI courses and specializations from Andrew Ng and industry experts\nLabs and quizzes to test your knowledge\nProjects to share with employers\nCertificates to testify to your new skills\nA community to help you advance at the speed of AI\nEnroll now to lock in a year of full access for $25 per month paid upfront, or opt for month-to-month payments at just $30 per month. Both payment options begin with a one week free trial. Explore Pro’s benefits and start building today!\nTry Pro Membership\nWant to know more about what matters in AI right now? \nRead \nthe latest issue\n of \nThe Batch\n for in-depth analysis of news and research.\nLast week, Andrew Ng talked about the importance of controlling your own data to leverage AI agents effectively, the challenges posed by SaaS vendors creating data silos, and the increasing value of organizing unstructured data for AI readiness. \n“Unfortunately, many SaaS vendors try to create a data silo in their customer’s business. By making it hard for you to extract your data, they create high switching costs. This also allows them to steer you to buy their AI agent services — sometimes at high expense and/or of low quality — rather than build your own or buy from a different vendor.”\nRead Andrew’s letter \nhere\n.\nOther AI news and research stories we covered that might scare you to your bones:\nOpenAI has completed a restructuring, \nfreeing it to go public and make deals with new partners\n, marking a significant milestone.\nMiniMax-M2 emerges as a leader in open-weights coding, \noffering top performance with a lightweight footprint and low costs\n.\nUniversal Music Group and music generator Udio have \nstruck a deal to settle a lawsuit and build a new platform to remix copyrighted music\n, signaling a new embrace of AI by the music industry.\nGoogle researchers released VaultGemma, \nan open-weights model designed to redact personal information\n, enhancing privacy in AI training sets.\nSubscribe to Data Points","images":[{"image_id":"meta-ai-now-recognizes-1600-languages_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/11/Automated-Speech-Recognition.png","local_path":null,"alt":"Two young adults in a conversation, one African and the other southeast Asian, in traditional dress, wearing microphone headsets"}]}
{"article_id":"training-power-laws-translate-to-robotics","title":"Training power laws translate to robotics: Amazon builds forecasting model to predict multiple scenarios","url":"https://www.deeplearning.ai/the-batch/training-power-laws-translate-to-robotics/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-11-07T10:59:00-08:00","body_text":"In today’s edition of Data Points, you’ll learn more about:\nStability AI’s limited wins in Getty copyright suit\nKosmos’s new generalist scientific research agent\nGerman Commons, a big open dataset for training AI models\nGoogle’s experiments putting satellites with AI chips in space\nBut first:\nHuge real-world datasets may establish new robotics scaling laws\nGeneralist AI introduced GEN-0, a class of embodied foundation models trained directly on physical interaction data that demonstrates predictable scaling laws similar to those in large language models. The company trained GEN-0 on over 270,000 hours of real-world manipulation data — orders of magnitude more than existing robotics datasets — and observed a phase transition at 7 billion parameters where smaller models exhibited ossification (inability to absorb new information) while larger models continued to improve. The models use a training approach that enables simultaneous thinking and acting by processing asynchronous streams of sensing and action tokens, and work across different robot configurations including six-, seven-, and 16+-degree-of-freedom semi-humanoid robots. The research demonstrates that pretraining data follows a power-law scaling relationship with downstream task performance, allowing researchers to predict how much data is needed to reach specific performance levels. (\nGeneralist AI\n)\nAmazon releases Chronos-2, a universal forecasting model\nChronos-2 can forecast single time series, multiple related time series, and time series influenced by external factors, all without needing extra training. The model uses in-context learning and a group attention feature to understand how different time series relate to each other and to factor in outside influences like weather or sales promotions. Amazon trained Chronos-2 on synthetic data since real-world datasets with complex relationships between variables are hard to find. Chronos-2 beat existing forecasting models by wide margins on two major benchmarks, winning over 90 percent of head-to-head comparisons against its predecessor, Chronos-Bolt. The model’s weights are now openly available, and earlier versions have been downloaded over 600 million times from Hugging Face. (\nAmazon\n)\nStability AI wins limited copyright judgment in image scraping case\nGetty Images largely lost its lawsuit against Stability AI in Britain’s High Court, though it narrowly won on trademark infringement claims. The image library company had accused Stability of scraping 12 million images from its website without permission to train the Stable Diffusion image generator, but Getty dropped its primary copyright claims during the trial and lost its secondary copyright arguments. The judge ruled that Stable Diffusion doesn’t infringe copyright because it doesn’t store or reproduce copyrighted works, but said Getty’s watermark appearing on some generated images constituted trademark infringement. Legal experts say the case leaves key questions about AI training and copyright unanswered, since Getty abandoned key claims before the judge could rule on whether using copyrighted material to train AI models is lawful. Getty is pursuing a separate copyright lawsuit against Stability in U.S. federal court. (\nAssociated Press\n)\nKosmos automates scientific research across multiple disciplines\nEdison Scientific authors introduced Kosmos, an AI system that automates data-driven discovery by performing iterative cycles of literature search, data analysis, and hypothesis generation. Given a dataset and research objective, Kosmos writes an average of 42,000 lines of code and reads 1,500 scientific papers per run—a nearly tenfold increase over previous systems. The authors listed seven discoveries, including identifying a clinically relevant mechanism of neuronal aging and generating statistical evidence that superoxide dismutase 2 may causally reduce myocardial fibrosis in humans. Expert evaluators found 79 percent of statements in Kosmos reports accurate, with 85 percent of data analysis-based statements reproducible, though the system showed limitations in interpretive statements. AI researchers in related fields may find Kosmos valuable since it demonstrates how structured world models can coordinate hundreds of agent rollouts to perform what experts estimated as more than six months of research work. (\narXiv\n)\nMassive open corpus of German text developed for AI training\nResearchers released the German Commons, the largest collection of openly licensed German text to date, comprising 154 billion tokens across 35.78 million documents from 40 institutional sources. The corpus draws from seven domains — web, political, legal, news, economic, cultural, and scientific — with all texts carrying verifiable licenses of at least CC-BY-SA 4.0. Processing included OCR-specific filtering for historical documents, deduplication, and removal of personal or toxic information. The release helps developers build German language models without the legal and ethical barriers posed by web crawls, providing commercially usable training data with verifiable provenance through document-level license metadata. The corpus and processing code are available on Hugging Face and GitHub. (\narXiv\n)\nGoogle tests AI infrastructure in space with solar-powered satellites\nGoogle announced Project Suncatcher, a research initiative investigating whether constellations of solar-powered satellites equipped with TPUs could one day scale machine learning compute in space. The company published a preprint paper detailing early progress on challenges including high-bandwidth communication between satellites, orbital dynamics, and radiation effects on computing hardware. Google’s team achieved 1.6 terabits per second transmission in a bench-scale demonstration and found that Trillium TPUs withstood radiation levels nearly three times higher than expected five-year mission doses. The research suggests that if launch costs continue declining to around $200 per kilogram by the mid-2030s, space-based data centers could become economically comparable on a per-kilowatt basis to Earth-bound facilities. Google plans to launch two prototype satellites in partnership with Planet by early 2027 to test the concepts in orbit. (\nGoogle\n)\nA special offer for our community\nDeepLearning.AI just launched the first-ever subscription plan for our entire course catalog! As a Pro Member, you’ll immediately enjoy access to:\nOver 150 AI courses and specializations from Andrew Ng and industry experts\nLabs and quizzes to test your knowledge \nProjects to share with employers \nCertificates to testify to your new skills\nA community to help you advance at the speed of AI\nEnroll now to lock in a year of full access for $25 per month paid upfront, or opt for month-to-month payments at just $30 per month. Both payment options begin with a one week free trial. Explore Pro’s benefits and start building today!\nTry Pro Membership\nStill want to know more about what matters in AI right now?\nRead \nthis week’s issue\n of The Batch for in-depth analysis of news and research.\nThis week, Andrew Ng talked about the importance of controlling your own data to leverage AI agents effectively, challenges posed by SaaS vendors creating data silos, and the increasing value of organized unstructured data.\n“Because of AI’s growing capabilities, the value you can now create from ‘connecting the dots’ between different pieces of data is higher than ever. For example, if an email click is logged in one vendor’s system and a subsequent online purchase is logged in a different one, then it is valuable to build agents that can access both of these data sources to see how they correlate to make better decisions.”\nRead Andrew’s full letter \nhere\n.\nOther top AI news and research stories we covered in depth:\nOpenAI has completed a restructuring, \nfreeing it to go public and make deals with new partners\n, marking a significant milestone.\nMiniMax-M2 emerges as a leader in open-weights coding, \noffering top performance with a lightweight footprint and low costs\n.\nUniversal Music Group and music generator Udio have \nstruck a deal to settle a lawsuit and build a new platform to remix copyrighted music\n, signaling a new embrace of AI by the music industry.\nGoogle researchers released VaultGemma, \nan open-weights model designed to redact personal information\n, enhancing privacy in AI training sets.\nSubscribe to Data Points","images":[{"image_id":"training-power-laws-translate-to-robotics_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/11/The-Batch-ads-and-exclusive-banners--61-.jpg","local_path":null,"alt":"Line of futuristic humanoid robots, getting gradually bigger from left to right"}]}
{"article_id":"openai-security-agent-finds-and-plugs-holes","title":"OpenAI security agent finds and plugs holes: Cognition’s SWE-1.5 model brings more speed for coding agents","url":"https://www.deeplearning.ai/the-batch/openai-security-agent-finds-and-plugs-holes/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-11-03T10:40:00-08:00","body_text":"In today’s edition of Data Points, you’ll learn more about:\nWhy Gemma’s been pulled from Google’s AI Studio\nHow Minimax built M2 for better coding performance\nA new technique for efficiently training smaller models\narXiv’s new requirements for computer science submissions\nBut first:\nOpenAI unveils new security agent for open-source projects\nOpenAI announced Aardvark, an autonomous GPT-5-powered agent that analyzes code repositories to discover security vulnerabilities, assess their severity, and propose patches. The system monitors code commits, creates threat models, uses sandbox environments to validate whether a bug can be exploited, and integrates with GitHub and Codex to deliver fixes without disrupting development. In benchmark testing, Aardvark identified 92 percent of known vulnerabilities and discovered ten issues in open-source projects that received Common Vulnerabilities and Exposures (CVE) identifiers. The tool addresses a growing challenge for developers — over 40,000 CVEs were reported in 2024 alone — by automating security research that traditionally requires specialized human expertise. Aardvark is now available through a private beta program, with OpenAI planning to offer free scanning for select non-commercial open-source projects. (\nOpenAI\n)\nCognition updates speedy coding model for Windsurf agents\nCognition’s Codeium team released SWE-1.5, a software engineering model with hundreds of billions of parameters that runs at up to 950 tokens per second. The company partnered with Cerebras to serve the model 6 times faster than Claude Haiku 4.5 and 13 times faster than Sonnet 4.5. Codeium trained the model using reinforcement learning on coding tasks with its Cascade agent harness, building on an open-source base model and deploying it on Nvidia’s GB200 chips. The model scored competitively on SWE-Bench Pro, a benchmark of coding tasks across different codebases. SWE-1.5 is available now in Windsurf, Codeium’s code editor. (\nCognition\n)\nGoogle pulls Gemma from AI Studio after defamation claims\nGoogle removed its open-weights Gemma model from AI Studio after U.S. Senator Marsha Blackburn said the model falsely accused her of sexual misconduct. In a letter to CEO Sundar Pichai, Blackburn said Gemma fabricated claims about a 1987 campaign incident involving a state trooper, though no such accusation exists and she didn’t run for office until 1998. The senator also referenced a lawsuit by conservative activist Robby Starbuck, who claims Google’s AI models generated defamatory statements calling him a “child rapist,” and argued these fabrications constitute defamation rather than harmless hallucinations. Google said it never intended Gemma to be used as a consumer tool for factual questions and will continue making the models available via API while removing them from AI Studio. (\nTechCrunch\n)\nMiniMax’s M2 outperforms other open-weight models\nChinese AI lab MiniMax released MiniMax-M2, an open-weight mixture-of-experts model with 230 billion total parameters but only 10 billion active at inference time. M2 ranks first among open models on Artificial Analysis’s composite intelligence benchmark and performs competitively with leading proprietary models on coding tasks like SWE-Bench Verified and agentic benchmarks like GAIA. M2’s smaller compute footprint enables faster feedback loops and allows developers to run more simultaneous agent instances on the same hardware budget. MiniMax made M2 available via API at $0.30/$1.20 per million input/output tokens and released the model weights on Hugging Face for local deployment. The company’s M2-based agent is also free for a limited period. (\nGitHub\n)\nNew distillation method promises more efficiently trained models\nResearchers at Thinking Machines showed that on-policy distillation — a training method that samples outputs from a student model and grades each token using a teacher model — achieves expert performance at a fraction of the cost of reinforcement learning. The technique combines the relevance of on-policy training with the dense feedback of distillation, allowing an 8 billion parameter model to reach 70 percent accuracy on the AIME ‘24 math benchmark with 9-30 times less compute than standard supervised fine-tuning. The researchers also showed on-policy distillation can restore instruction-following abilities lost during specialized training, making it useful for continual learning and model personalization. This approach could enable practitioners to train high-performing specialized models without the computational expense of large-scale RL, while maintaining the ability to update models with new knowledge over time. (\nThinking Machines\n)\nArXiv restricts AI-generated survey and position paper submissions\nArXiv’s computer science section will now only accept review articles and position papers that have already passed peer review at a journal or conference. Authors must provide documentation of successful peer review when submitting, or their papers will likely be rejected. The change aims to help moderators manage an “unmanageable influx” of such papers, many of which arXiv describes as low-quality and likely generated with the help of large language models. ArXiv emphasizes that review and position papers were never officially accepted content types, though moderators previously approved high-quality submissions at their discretion. arXiv says these rules will free up volunteer moderators to focus on research papers, which remain the platform’s core mission. (\narXiv\n)\nA special offer for our community\nDeepLearning.AI just launched the first-ever subscription plan for our entire course catalog! As a Pro Member, you’ll immediately enjoy access to:\nOver 150 AI courses and specializations from Andrew Ng and industry experts\nLabs and quizzes to test your knowledge\nProjects to share with employers\nCertificates to testify to your new skills\nA community to help you advance at the speed of AI\nEnroll now to lock in a year of full access for $25 per month paid upfront, or opt for month-to-month payments at just $30 per month. Both payment options begin with a one week free trial. Explore Pro’s benefits and start building today!\nTry Pro Membership\nWant to know more about what matters in AI right now?\nRead \nthe latest issue\n of \nThe Batch\n for in-depth analysis of news and research.\nLast week, Andrew Ng talked about launching DeepLearning.AI Pro, a membership offering access to over 150 AI programs, including new courses and tools to help build AI applications.\n“Beyond courses, I’m working on new tools to help you build AI applications and grow your career (and have fun doing so!). Many of these tools will be available first to DeepLearning.AI Pro members. So please join to be the first to hear about these new developments!”\nRead Andrew’s letter \nhere\n.\nOther AI news and research stories we covered that might scare you to your bones:\nChatbots could lead users into rabbit holes\n as they intertwine with paranoia and delusions, raising concerns about mental health impacts of AI.\nExperts warn that \nthe AI boom is bound to bust\n if the massive investments in AI models and infrastructure fail to deliver expected returns.\nThe landscape of AI training faces challenges as \nweb data diminishes\n, with online publishers potentially restricting access to valuable data.\nAutonomous systems wage war\n with drones reshaping modern combat and sparking fears over the potential loss of human oversight.\nSubscribe to Data Points","images":[{"image_id":"openai-security-agent-finds-and-plugs-holes_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/11/Security-Researcher-Finding-Holes.png","local_path":null,"alt":"A computer scientist at her desktop, using an AI agent program to find and fix security holes"}]}
{"article_id":"cursor-introduces-a-new-model-built-for-agents","title":"Cursor introduces a new model built for agents: Claude models sometimes know they’ve been tampered with","url":"https://www.deeplearning.ai/the-batch/cursor-introduces-a-new-model-built-for-agents/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-10-31T10:31:00-07:00","body_text":"In today’s edition of Data Points, you’ll learn more about:\nGitHub Copilot’s new agentic tools\nOpenAI’s new open classification policy model\nIBM’s small but powerful Granite Nano models\nThe state of generative media\nA brand-new way to learn from DeepLearning.AI\nBut first:\nCursor updates with new coding model and multi-agent interface\nCursor released Composer, its first coding model, plus a redesigned interface for running multiple AI agents simultaneously. Composer completes most coding tasks in under 30 seconds, advertised as 4 times faster than similarly capable models, and includes codebase-wide semantic search for working in large projects. The new Cursor interface centers around agents rather than files, allowing developers to run multiple agents in parallel using git worktrees or remote machines. Cursor 2.0 also introduces improved code review tools and a native browser feature that lets agents test their own work and iterate on changes. Cursor includes free plans with limited features and paid plans starting at $16/month. (\nCursor\n)\nAnthropic examines introspective awareness in top models\nAnthropic published research showing that Claude models can sometimes detect and identify concepts artificially injected into their neural activity patterns. Using a technique called “concept injection,” interpretability experts inserted specific neural patterns — for example, representations of “all caps” or “bread” — into the model’s activations. They found that Claude Opus 4 and 4.1 correctly recognized these injections about 20 percent of the time, often before mentioning the concept in their output. The models also showed some ability to modulate their internal representations in response to instructions like “think about X” versus “don’t think about X,” and could determine whether outputs were intentional by checking their prior neural activity. While this introspective capability remains highly unreliable and limited in scope, the authors note that the most capable models tested performed best, suggesting introspection may improve as AI systems become more sophisticated. The findings could eventually help make AI systems more transparent by enabling them to explain their reasoning, though the authors caution that models might still fail to notice some internal processes or even learn to misrepresent their thinking. (\nAnthropic\n)\nAgent HQ integrates multiple agents into GitHub and VS Code\nGitHub announced Agent HQ, a platform that brings coding agents from Anthropic, OpenAI, Google, Cognition, and xAI directly into GitHub. The system includes a “mission control” interface across GitHub, VS Code, mobile, and CLI that lets developers assign work to multiple agents and track their progress. New features include Plan Mode in VS Code, which helps developers create step-by-step project plans before writing code, and AGENTS.md files for customizing agent behavior with specific rules and preferences. The new agent capabilities are available for paid Copilot subscribers in GitHub, VS Code, and the Copilot CLI. (\nGitHub\n)\nOpenAI and ROOST release open-weight safety models\nOpenAI launched gpt-oss-safeguard in two sizes (120 billion and 20 billion parameters) as open-weight models under an Apache 2.0 license. The models use chain-of-thought reasoning to classify content according to developer-provided policies at inference time, eliminating the need to retrain classifiers when policies change. OpenAI developed the approach internally as “Safety Reasoner,” which now accounts for up to 16 percent of total compute in some recent launches. The models outperformed GPT-5 Thinking on internal multi-policy accuracy tests despite their smaller size. Both models are available now on Hugging Face. (\nOpenAI\n)\nIBM’s Granite 4.0 Nano models target the edge\nIBM released Granite 4.0 Nano, a collection of four small language models ranging from 350 million to 1.5 billion parameters, designed for edge computing and on-device applications. The models include two with a new hybrid-SSM architecture and two traditional transformer versions, all trained on over 15 trillion tokens and released under an Apache 2.0 license. Benchmarks show the Nano models outperform similarly sized competitors from Alibaba, LiquidAI, and Google on tasks including general knowledge, math, code, safety, instruction following, and tool calling. All four are available on Hugging Face. (\nHugging Face\n)\nSurvey says Google leads generative media model adoption\nAn Artificial Analysis survey of 200-plus users and organizations found Google’s Gemini and Veo models led adoption for image and video generation respectively, with 74 percent of respondents using Gemini and 69 percent using Veo. Quality ranked as the top factor in model selection for both personal and organizational use, while cost proved especially critical for organizations choosing video generation APIs; 58 percent cited lower total cost as their primary consideration when selecting access channels. Organizations split nearly evenly between accessing models through applications (65 percent) and APIs (62 percent), while personal users overwhelmingly preferred applications (86 percent). The survey, conducted in Q3 2025 before OpenAI’s Sora 2 release, found 65 percent of organizations reported return on investment within 12 months, with 34 percent already seeing ROI from their generative media initiatives. (\nArtificial Analysis\n)\nA special offer for our community\nDeepLearning.AI just launched the first-ever subscription plan for our entire course catalog! As a Pro Member, you’ll immediately enjoy access to:\nOver 150 AI courses and specializations from Andrew Ng and industry experts\nLabs and quizzes to test your knowledge \nProjects to share with employers \nCertificates to testify to your new skills\nA community to help you advance at the speed of AI\nEnroll now to lock in a year of full access for $25 per month paid upfront, or opt for month-to-month payments at just $30 per month. Both payment options begin with a one week free trial. Explore Pro’s benefits and start building today!\nTry Pro Membership\nStill want to know more about what matters in AI right now?\nRead \nthis week’s special Halloween issue\n of \nThe Batch\n for in-depth analysis of news and research, including some tricks and treats.\nThis week, Andrew Ng talked about launching DeepLearning.AI Pro, a new membership offering access to over 150 AI programs, plus exclusive courses and tools to help build AI applications.\n“All of DeepLearning.AI’s course videos remain free to view on our platform. Pro membership adds that critical hands-on learning: Labs to build working systems from scratch, practice questions to hone your understanding, and certificates to show others your skills.” \nRead Andrew’s full letter \nhere\n. \nOther AI news and research stories we covered that might scare you to your bones:\nChatbots could lead users into rabbit holes\n as they intertwine with paranoia and delusions, raising concerns about mental health impacts of AI.\nExperts warn that \nthe AI boom is bound to bust\n if the massive investments in AI models and infrastructure fail to deliver expected returns.\nThe landscape of AI training faces challenges as \nweb data diminishes\n, with online publishers potentially restricting access to valuable data.\nAutonomous systems wage war\n with drones reshaping modern combat and sparking fears over the potential loss of human oversight.\nSubscribe to Data Points","images":[{"image_id":"cursor-introduces-a-new-model-built-for-agents_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/10/Coffee-Shop-Watching-Videos.png","local_path":null,"alt":"Four people at a coffee shop read books and watch video on their laptops while a TV plays behind them"}]}
{"article_id":"lerobot-adds-support-for-pi-and-nvidia-models","title":"LeRobot adds support for PI and Nvidia models: Qualcomm squares off with Nvidia in AI inference","url":"https://www.deeplearning.ai/the-batch/lerobot-adds-support-for-pi-and-nvidia-models/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-10-27T11:47:00-07:00","body_text":"In today’s edition of Data Points, you’ll learn more about:\nGitHub Copilot’s new code completion model\nOpenAI’s acquisition of a top computer use company\nAnthropic’s latest deal for more computing power\nManus’s updated agentic assistant\nBut first:\nHugging Face updates its LeRobot open-source robotics platform\nHugging Face launched LeRobot v0.4.0, featuring improved data processing pipelines, updated capabilities for handling massive datasets, new dataset editing tools, and support for Libero and Meta-World simulation environments. The release integrates advanced Vision-Language-Action models including Physical Intelligence’s π0 and π0.5 and Nvidia’s GR00T N1.5. It also adds simplified multi-GPU training through Accelerate, introduces a plugin system for easier hardware integration, and adds support for 180 manipulation tasks. The goal is to make robot learning more scalable and accessible to developers, advancing open-source robotics research. Hugging Face also launched a free, open-source Robot Learning Course to accompany the release. (\nHugging Face\n)\nQualcomm reveals details on new AI accelerator chips\nQualcomm’s chips are designed to compete with Nvidia in the data center market, with the AI200 launching in 2026 and the AI250 in 2027. The chips, based on Qualcomm’s smartphone neural processing units, will be available in full liquid-cooled server rack systems and focus on inference rather than training AI models. Qualcomm claims its systems will cost less to operate than competitors and support 768 gigabytes of memory, more than current offerings from Nvidia and AMD. The announcement represents significant new competition in the AI chip market, where nearly $6.7 trillion in capital expenditures will be spent on data centers through 2030, according to McKinsey estimates. Qualcomm has already partnered with Saudi Arabia’s Humain to deploy systems using up to 200 megawatts of power. (\nCNBC\n)\nGitHub Copilot rolls out improved custom code completion model\nGitHub’s updated Copilot model shows 20 percent more accepted and retained characters, a 12 percent higher acceptance rate, 3x higher throughput, and 35 percent lower latency. The company trained the model on nearly 10 million repositories across 600-plus programming languages. The developers used mid-training to incorporate modern APIs and syntax, supervised fine-tuning for fill-in-the-middle completion, and reinforcement learning to reward code quality and relevance. The company evaluated models through offline benchmarks, internal testing with language experts, and A/B testing with developers. The updated model now powers GitHub Copilot across all editors and environments. (\nGitHub\n)\nOpenAI acquires company behind Sky, a desktop computer use app\nOpenAI bought Software Applications Incorporated on Thursday, acquiring Sky, a Mac app that reads screen content and performs actions in applications. The entire Sky team joined OpenAI to integrate Sky’s capabilities into ChatGPT. The acquisition came two days after OpenAI launched ChatGPT Atlas, an AI-powered browser for Mac, forming a strategy to control both web browsing and native Mac applications. The move puts OpenAI in direct competition with Anthropic’s Claude computer use features, Microsoft’s Windows-embedded Copilot, and Google’s agent-like capabilities as companies race to develop AI that can perform tasks directly on users’ computers. (\nOpenAI\n)\nAnthropic strikes cloud deal with Google for up to 1 million AI chips\nThe multi-year expansion will bring over a gigawatt of capacity online in 2026 with more to follow. The additional capacity will enable more thorough testing, alignment research, and help meet growing demand for Claude while keeping the model competitive. Anthropic’s unusual multi-platform compute strategy combines Google’s TPUs, Amazon’s Trainium chips, and NVIDIA’s GPUs for inference, plus a primary partnership with Amazon for training and cloud infrastructure. Specific terms of the deal were undisclosed, but both companies said the cloud capacity was worth tens of billions of dollars. (\nAnthropic\n)\nManus AI updates its AI agent system, adds webapp capabilities\nManus 1.5 introduces full-stack web application development, enabling users to build and deploy production-ready apps with backends, databases, user authentication, and embedded AI capabilities entirely through conversation. The release includes two models, Manus-1.5 and Manus-1.5-Lite. Both support new collaboration features and a centralized library for organizing generated files. The update reduces average task completion time from 15 minutes to under 4 minutes, a nearly four-fold improvement, while improving task quality and user satisfaction on internal benchmarks. Manus-1.5-Lite is available to all users, while Manus-1.5 requires a subscription ($16/month). (\nManus AI\n)\nWant to know more about what matters in AI right now?\nRead \nthe latest issue\n of \nThe Batch\n for in-depth analysis of news and research.\nLast week, Andrew Ng talked about the necessity of a disciplined evals and error analysis process for effective agentic AI development, methods for identifying performance issues in AI workflows, and the changing design of workflows as LLMs improve.\n“Assuming we are automating a task where human-level performance (HLP) is desirable, then the most important thing is to systematically examine traces to understand when the agent is falling short of HLP. And just as we can get started with evals using a quick-and-dirty initial cut at it (maybe using just a handful of examples) followed by iterating to improve, so too with error analysis.”\nRead Andrew’s letter \nhere\n.\nOther top AI news and research stories covered in depth:\nAnt Group’s Ling-1T, \nan open, non-reasoning model that outperformed closed competitors\n, challenging expectations in AI reasoning.\nSecurity experts identified \nholes in the popular Model Context Protocol\n, raising concerns about potential data access by attackers.\nCalifornia took a significant step by \npassing four AI transparency bills in less than one month\n, re-shaping AI regulation in the U.S.\nResearchers introduced GEPA, \nan algorithm for better prompts to improve agentic systems’ performance\n, enhancing AI’s effectiveness at multiple tasks.\nSubscribe to Data Points","images":[{"image_id":"lerobot-adds-support-for-pi-and-nvidia-models_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/10/Server-Rack.png","local_path":null,"alt":"Technician in data center monitors server racks with digital tablet, ensuring network efficiency and system uptime."}]}
{"article_id":"atlas-ushers-in-openais-browser-era","title":"Atlas ushers in OpenAI’s browser era: DeepSeek’s efficient new OCR model","url":"https://www.deeplearning.ai/the-batch/atlas-ushers-in-openais-browser-era/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-10-24T10:49:49-07:00","body_text":"Welcome back! In today’s edition of Data Points, you’ll learn more about:\nClaude Code’s launch on the web and mobile\nReddit’s lawsuit against Perplexity and web-scraping firms\nMeta and Hugging Face’s secure environments for agents\nGigaBrain’s use of world models to better train robots\nBut first:\nOpenAI launches its own agentic web browser\nOpenAI released ChatGPT Atlas, a new web browser that integrates ChatGPT and agent mode directly into the application. Atlas’s AI can understand page content, remember context across sessions, and complete tasks without users leaving their current page. The browser includes an optional “browser memories” feature that lets ChatGPT recall details from previously visited sites to provide more personalized assistance, but users control what information is stored or deleted. Atlas also features agent mode in preview for paid users, enabling ChatGPT to autonomously do web research, fill shopping carts, or compile documents in the browser. Atlas reflects OpenAI’s push toward agentic AI systems that can handle routine computing tasks, though the company acknowledges risks including mistakes and vulnerability to malicious instructions. ChatGPT Atlas is available now on macOS for Free, Plus, Pro, and Go users, with Windows, iOS, and Android versions coming soon. (\nOpenAI\n and \nX\n)\nDeepSeek pilots text-compressing optical character recognition model\nDeepSeek released DeepSeek-OCR, a vision-language model that converts text documents into compact visual representations using far fewer tokens than the original text. The model achieves 97 percent accuracy when compressing text at a 10-to-1 ratio and maintains 60 percent accuracy even at 20-to-1 compression by rendering text as images and encoding them into visual tokens that language models decode back into text. On the OmniDocBench benchmark, DeepSeek-OCR outperforms competing models while using significantly fewer tokens — just 100 tokens per page compared to 256 for GOT-OCR2.0 and fewer than 800 tokens versus over 6,000 for MinerU2.0. This compression technique could enable more efficient processing of long contexts in large language models by converting older conversation history into progressively smaller images, similar to how human memory fades over time. The model’s code and weights are publicly available on GitHub. (\narXiv\n and \nGitHub\n)\nClaude Code launches on the web with parallel agents in the cloud\nAnthropic released a web-based version of Claude Code that lets developers run multiple coding tasks simultaneously across different GitHub repositories from their browser. The service operates on Anthropic-managed cloud infrastructure, with each task running in an isolated sandbox environment that includes network and filesystem restrictions to protect code and credentials. As with the command-line and IDE versions, developers can use Claude Code’s web interface for bug fixes, routine tasks, testing, backend changes, pull requests, and documentation. The cloud-based approach, similar to OpenAI’s Codex, suggests a shift toward AI agents handling development work independently in managed environments, rather than requiring developers to run coding assistants locally on their own machines, potentially making development more accessible while introducing new security challenges. (Anthropic also launched an early mobile version of Claude Code in its iOS app.) Claude Code for Web is available now in research preview for Claude Pro and Max subscribers. (\nAnthropic\n)\nReddit accuses Perplexity AI and scraping firms of data theft\nReddit sued Perplexity AI and three other companies — Oxylabs, AWMProxy, and SerpApi — alleging they illegally scraped millions of user comments for commercial use. The lawsuit, filed in New York federal court, accuses the companies of bypassing Reddit’s anti-scraping protections and extracting content from Google’s search results when direct access was blocked. Reddit used a novel technique, creating a test post that could only be crawled by Google search, then showing that within hours, data from the post appeared on Perplexity. The lawsuit highlights tensions over how AI companies acquire training data, as Reddit has separately licensed its content to Google and OpenAI for payment and sued Anthropic alleging unauthorized scraping. Perplexity and the other defendants denied the allegations and said they would defend themselves in court. (\nAssociated Press\n and \nThe New York Times\n)\nMeta and Hugging Face launch hub for shared agentic environments\nOpenEnv Hub is a new community platform where developers can build, share, and explore standardized environments for AI agents. Agentic environments define the tools, APIs, credentials, and execution context an agent needs to perform specific tasks in secure, sandboxed settings that work for both training and deployment. The hub launches soon with initial environments that developers can test by interacting as human agents or enlisting models to solve tasks, while an OpenEnv 0.1 specification has already been released for community feedback. The initiative addresses a key challenge in AI agent development: large language models need access to appropriate tools, but exposing millions of tools directly isn’t safe or practical, requiring instead carefully defined environments with clear semantics and security guarantees. Meta is integrating OpenEnv with its TorchForge RL library and collaborating with open-source projects including verl, TRL, and SkyRL to expand compatibility. (\nHugging Face\n)\nGigaBrain-0 uses synthetic data to train more capable robots\nResearchers introduced GigaBrain-0, a vision-language-action model that trains robots using synthetic data generated by world models rather than expensive real-world demonstrations. The system generates training scenarios by altering object appearances, placements, lighting conditions, and camera viewpoints, getting more diverse training data than most robots get from real-world observation. GigaBrain-0 incorporates depth sensing for spatial reasoning and uses “embodied Chain-of-Thought” supervision to break complex tasks into intermediate steps. Tests on arm manipulation, long tasks, and mobile manipulation showed GigaBrain-0 outperformed the baseline π0 model by 10–30 percent. The team also released GigaBrain-0-Small, a lightweight version that runs 10 times faster on edge devices while maintaining comparable performance. (\narXiv\n and \nGitHub\n)\nStill want to know more about what matters in AI right now? \nRead \nthis week’s issue\n of \nThe Batch\n for in-depth analysis of news and research.\nThis week, Andrew Ng talked about the importance of error analysis in agentic AI development, best practices for identifying and addressing performance gaps in AI workflows, and the evolving nature of workflow design due to rapid improvements in LLMs.\n“A basic error analysis procedure might involve gathering a sample set of topics where the output is subpar, and reading the results of every step of the workflow — called the traces — to see which step most frequently generated results materially worse than a human would have. This is very valuable for deciding what step to focus on improving.” \nRead Andrew’s full letter \nhere\n.\nOther top AI news and research stories we covered in depth:\nAnt Group’s Ling-1T, \nan open, non-reasoning model that outperformed closed competitors\n, challenging expectations in AI reasoning.\nSecurity experts identified \nholes in the popular Model Context Protocol\n, raising concerns about potential data access by attackers.\nCalifornia took a significant step by \npassing four AI transparency bills in less than one month\n, re-shaping AI regulation in the U.S.\nResearchers introduced GEPA, \nan algorithm for better prompts to improve agentic systems’ performance\n, enhancing AI’s effectiveness at multiple tasks.\nSubscribe to Data Points","images":[{"image_id":"atlas-ushers-in-openais-browser-era_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/10/Whisk_71cf939e19418ec9b8946abbc22da88ddr.jpeg","local_path":null,"alt":"A humanoid robot sits in a library, reading a book, surrounded by stacks with a laptop displaying code."}]}
{"article_id":"skills-remakes-claude-with-custom-instructions","title":"Skills remakes Claude with custom instructions: Google’s Veo 3.1 adds native audio and new editing tools","url":"https://www.deeplearning.ai/the-batch/skills-remakes-claude-with-custom-instructions/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-10-20T11:14:00-07:00","body_text":"In today’s edition of Data Points, you’ll learn more about:\nMicrosoft’s Copilot Voice and Vision for Windows 11\nHunyuanImage-3.0, a leaderboard-topping image generator\nAdobe’s new plan for custom Firefly models\nLing-1T, an open non-thinking model that shines at reasoning\nBut first:\nAnthropic launches Skills to customize Claude\nSkills are portable folders containing instructions, scripts, and resources that Claude automatically loads when relevant to a task at hand, keeping the model fast while it accesses specialized instructions and expertise. The feature works across all Claude products, from Claude apps (for Pro, Max, Team, and Enterprise users) to the Messages API and Claude Code, and multiple skills can stack together for complex workflows. By extending Claude’s capabilities beyond its base training, Anthropic hopes that Skills, like MCP, may become a standard way for advanced users (and their teammates) to interact with an AI model. Users can access Anthropic-created skills for common tasks like creating Excel spreadsheets and PowerPoint presentations, customize example skills from GitHub, or build their own using the skill-creator tool. (\nAnthropic\n)\nGoogle updates Veo with audio generation and new editing tools\nGoogle released Veo 3.1, an updated version of its video generation model that adds generated audio and tops other video models on multiple benchmarks. Google’s video editor Flow also has new tools: “Ingredients to Video,” “Frames to Video,” and “Extend” can edit previously created videos without sound. Veo 3.1 also includes new editing capabilities: an “Insert” tool that adds elements to scenes while adjusting lighting and shadows, and a forthcoming “Remove” feature for erasing objects from videos. Veo 3.1 is available through the Gemini API, Vertex AI, the Gemini app, and Flow, with eight seconds of standard video costing about $3. (\nGoogle\n)\nMicrosoft integrates voice and vision AI into Windows 11\nMicrosoft’s latest OS update brings Copilot Voice and Copilot Vision capabilities to all Windows 11 PCs. Users can now activate Copilot with a “Hey Copilot” wake word and ask questions using natural language. Copilot Vision analyzes what’s on screen to provide guidance for tasks like troubleshooting, learning new apps, or editing projects. Microsoft says it hopes to make AI interaction as fundamental to computing as the mouse and keyboard (and also to sell lots of upgrades from the now-deprecated Windows 10). The new Copilot tools are available now for Windows 11 users via the Microsoft Store, with additional updates rolling out to Windows Insiders and Copilot Labs in the coming months. (\nMicrosoft\n)\nTencent’s HunyuanImage-3.0 is a best-in-class text-to-image model\nHunyuanImage-3.0 uses an autoregressive architecture instead of the diffusion transformer (DiT) approach common in most current image generators. (OpenAI’s GPT-Image is another exception.) Tencent’s model employs a Mixture of Experts design with 64 experts and 80 billion total parameters, activating 13 billion parameters per token, making it the largest open MoE model for image generation. The unified architecture allows the model to reason about prompts and automatically expand brief descriptions with contextually relevant details drawn from its training data. HunyuanImage-3.0 currently tops LMArena’s image generator leaderboard, beating Google’s Nano Banana, GPT-Image, and other leading closed models. (\nHugging Face\n)\nAdobe introduces AI Foundry to customize Firefly for enterprises\nAI Foundry retrains Adobe’s Firefly AI model with enterprise customers’ proprietary data, brand guidelines, and visual assets. Unlike Adobe’s existing custom Firefly models, which handle single concepts and image generation only, AI Foundry models will be multimodal and can understand multiple kinds of input simultaneously. Adobe teams work directly with clients to identify, transfer, and tag data before retraining the base Firefly model through a process called “continuous pre-training,” which the company describes as “deep tuning” rather than standard fine-tuning. The service aims to meet enterprise demand for more sophisticated AI customization while keeping client data separate and ensuring companies retain ownership of generated images. Early customers include Home Depot and Walt Disney Imagineering, with models deployed through Adobe’s Firefly Services API. (\nVentureBeat\n)\nLing-1T rivals GPT-5 in reasoning benchmarks\nA Chinese research team released Ling-1T, a 1 trillion parameter AI model that uses 50 billion active parameters per token and was trained on over 20 trillion tokens. The model outperformed open-weights competitors like DeepSeek-V3.1 and is competitive with proprietary systems including GPT-5 and Gemini 2.5 Pro at mathematics, coding, and logical reasoning tasks. Ling-1T makes several atypical technical choices, including FP8 mixed-precision training for 15 percent faster performance, an “evolutionary chain-of-thought” training process, and a sentence-level reinforcement learning method called LPO that treats sentences rather than individual tokens as semantic units. Ling-1T is the largest FP8-trained foundation model to date and shows that open-source non-thinking models can match proprietary systems in complex reasoning while maintaining greater efficiency and transparency. The model is available for download at Hugging Face and ModelScope, but API pricing and commercial availability details were not announced. (\nHugging Face\n)\nWant to know more about what matters in AI right now?\nRead \nthe latest issue\n of \nThe Batch\n for in-depth analysis of news and research.\nLast week, Andrew Ng talked about the importance of disciplined evaluation and error analysis in AI development, emphasized that understanding root causes of errors can lead to faster progress, and introduced best practices for evaluating agentic systems.\n“Rather than defining an error metric ahead of time, it is therefore typically more effective to first quickly build a prototype, then manually examine a handful of agent outputs to see where it performs well and where it stumbles. This allows you to focus on building datasets and error metrics — sometimes objective metrics implemented in code, and sometimes subjective metrics using LLM-as-judge — to check the system’s performance in the dimensions you are most concerned about.”\nRead Andrew’s letter \nhere\n.\nOther top AI news and research stories covered in depth:\nOpenAI strengthened its ties with AMD through \na multi-billion dollar chip deal\n, providing OpenAI six gigawatts of computing power and up to 10% of AMD stock.\nDeepSeek cut inference costs with \nDeepSeek-V3.2-Exp\n, which streamlines processing using a \"Lightning Indexer\" to boost efficiency.\nThinking Machines simplified fine-tuning with \nthe new Tinker API\n, making it easier to fine-tune models on many GPUs.\nMolmoAct enhanced robotic capabilities by \ncreating spatial maps\n, allowing robots to plot their actions before executing text directions.\nSubscribe to Data Points","images":[{"image_id":"skills-remakes-claude-with-custom-instructions_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/10/Whisk_66fd4d1783e773baf2e49e03ef411522eg.png","local_path":null,"alt":" Engaged in multitasking, man blends gaming with finance; sleek home office highlights tech and data trends."}]}
{"article_id":"claudes-haiku-boasts-top-performance-fast","title":"Claude’s Haiku Boasts Top Performance, Fast: Open speech recognition models top new leaderboard","url":"https://www.deeplearning.ai/the-batch/claudes-haiku-boasts-top-performance-fast/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-10-17T12:50:00-07:00","body_text":"In today’s edition of Data Points, you’ll learn more about:\nAlibaba’s small, edge-optimized vision-language models\nMicrosoft’s new image generator\nGitHub’s free kit for spec-driven development\nChatGPT’s new automated memory manager\nBut first:\nAnthropic updates Claude’s Haiku small model to 4.5\nAnthropic claims the new Haiku 4.5 performs coding tasks at levels comparable to Claude Sonnet 4 from five months ago while costing one-third as much and running more than twice as fast. The model outperforms Sonnet 4 in areas like computer use, basic math, and agentic coding. The release shows how AI capabilities that were recently considered advanced are becoming cheaper and faster to deploy, making them better suited for agentic applications. Claude Haiku 4.5 costs $1 per million input tokens and $5 per million output tokens, and is available through the Claude API, Amazon Bedrock, and Google Cloud Vertex AI. (\nAnthropic\n)\nNew leaderboard benchmarks speech recognition systems \nResearchers at Hugging Face launched the Open ASR Leaderboard, a reproducible benchmark that evaluates over 60 open-source and proprietary automatic speech recognition systems across 11 datasets, including multilingual transcription and long-form audio. The benchmark reports both word error rate (WER) and inverse real-time factor (RTFx), enabling fair comparisons of both accuracy and processing speed. For English transcription, conformer encoders paired with large language model decoders achieved the best average WER but processed audio more slowly, while CTC and TDT decoders delivered significantly better speed — up to 6,400 times faster than real-time — making them more practical for long-form and offline transcription. Nvidia’s open Canary and Parakeet models top the leaderboard for accuracy and speed respectively; surprisingly, proprietary models tend to trail open models on both benchmarks. (\narXiv\n and \nHugging Face\n)\nAlibaba releases smaller and quantized vision-language models\nAlibaba’s Qwen team released Qwen3-VL models at 4 billion and 8 billion parameter scales, each available in Instruct and Thinking variants, plus FP8-quantized versions for low-VRAM deployment. The models retain most of the capabilities of larger Qwen3-VL releases, from context window to GUI agent control. The FP8 checkpoints deliver near-BF16 performance, though Transformers does not yet support direct loading—deployment requires vLLM or SGLang. The release complements Qwen’s existing 30B and 235B mixture-of-experts tiers with smaller models suitable for single-GPU and edge deployments. The models are now available under open licenses on Hugging Face and GitHub. (\nHugging Face\n)\nMicrosoft releases first in-house text-to-image generation model\nMAI-Image-1 debuted in the top 10 on the LMArena text-to-image leaderboard. (Currently, it’s ninth.) Microsoft says its model specializes in photorealistic imagery, including complex lighting effects and landscapes, while maintaining faster generation speeds than many larger competing models. The release follows Microsoft’s announcement of its first two in-house models in August, part of the company’s strategy to build purpose-built AI models for integration into its products. (\nMicrosoft\n)\nGitHub open sources Spec Kit to improve coding agent reliability\nGitHub’s Spec Kit works with AI coding agents like GitHub Copilot, Claude Code, and Gemini CLI. The toolkit addresses a common problem: coding agents often produce code that appears correct but fails to work properly because developers treat them like search engines rather than literal-minded collaborators that need clear instructions. Spec Kit introduces a four-phase process (Specify, Plan, Tasks, and Implement), where specifications become editable documents that guide code generation, with built-in checkpoints for developers to verify and refine AI output at each stage. The approach proves especially useful for greenfield projects, adding features to existing codebases, and modernizing legacy systems by separating stable requirements from flexible implementation details. The toolkit is available now on GitHub. (\nGitHub\n)\nChatGPT updates memory management to prioritize by relevance\nChatGPT now automatically manages saved memories by keeping the most relevant details prioritized while moving less important information to the background, preventing accounts from reaching “memory full” status. The system determines which memories to prioritize based on recency and how frequently users discuss particular topics. Users can search their saved memories, sort them by date, manually adjust which memories are prioritized, and restore previous versions of saved memories. The feature also allows users to disable automatic memory management and view which memories are currently top of mind. As of this writing, OpenAI is rolling out the update to Plus and Pro subscribers globally on the web. (\nOpenAI\n)\nStill want to know more about what matters in AI right now?\nRead \nthis week’s issue\n of \nThe Batch\n for in-depth analysis of news and research.\nThis week, Andrew Ng talked about the importance of disciplined evaluation and error analysis in AI development, emphasizing that understanding root causes of errors can lead to faster progress, and introduced best practices for evaluating agentic systems.\n“With generative AI, a lot of intuitions from evals and error analysis of supervised learning carry over — history doesn’t repeat itself, but it rhymes — and developers who are already familiar with machine learning and deep learning often adapt to generative AI faster than people who are starting from scratch. But one new challenge is that the space of outputs is much richer, so there are many more ways an algorithm’s output might be wrong.”\nRead Andrew’s full letter \nhere\n.\nOther top AI news and research stories we covered in depth:\nOpenAI strengthened its ties with AMD through \na multi-billion dollar chip deal\n, providing six gigawatts of computing power and up to 10% of AMD's resources.\nDeepSeek cut inference costs with \nDeepSeek-V3.2-Exp\n, which streamlines processing using a \"Lightning Indexer\" to boost efficiency.\nThinking Machines simplified fine-tuning with \nthe new Tinker API\n, making it easier to fine-tune models on many GPUs.\nMolmoAct enhanced robotic capabilities by \ncreating spatial maps\n, allowing robots to plot their actions before executing text directions.\nSubscribe to Data Points","images":[{"image_id":"claudes-haiku-boasts-top-performance-fast_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/10/Whisk_6b1e1a299c2ea608a724122dbeef99c5eg.png","local_path":null,"alt":"Engaging podcast dialogue in soundproof studio, hosts using microphones and digital tablets during discussion."}]}
{"article_id":"figure-ai-unveils-its-third-generation-robot","title":"Figure AI unveils its third-generation robot: Microsoft’s healthcare data partnership with Harvard","url":"https://www.deeplearning.ai/the-batch/figure-ai-unveils-its-third-generation-robot/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-10-13T11:52:00-07:00","body_text":"In today’s edition of Data Points, you’ll learn more about:\nAI companies’ dominance of global venture funding\nSamsung’s 7-million-parameter Tiny Recursion Model\nThe U.S.–UAE agreement for 500,000 Nvidia GPUs annually\nIBM’s embrace of Anthropic’s Claude models for enterprise\nBut first:\nMicrosoft partners with Harvard to reduce dependence on OpenAI\nMicrosoft is collaborating with Harvard Medical School to enhance its Copilot chatbot with credible healthcare information, aiming to deliver a better healthcare offering than rival AI chatbots and build the brand of its Copilot assistant. The updated Copilot, launching this month, will draw on content from Harvard Health Publishing to answer medical queries, with Microsoft paying a licensing fee. The company is training its own models with the goal of eventually replacing workloads that currently rely on OpenAI's models, though this may take years. (\nThe Wall Street Journal\n)\nOpenAI enables third-party apps to run inside ChatGPT\nOpenAI introduced apps that users can access directly within ChatGPT conversations, along with an Apps SDK that developers can use to build these apps. Users can call up apps by name (such as \"Canva, design a poster\") or have ChatGPT suggest relevant apps during conversation. Initial partners include Booking.com, Coursera, Figma, and Spotify. The Apps SDK builds on the Model Context Protocol, an open standard that allows ChatGPT to connect to external tools and data. OpenAI will begin accepting app submissions for review later this year and plans to share monetization guidance soon, including ways for developers to charge users through its Agentic Commerce Protocol. (\nOpenAI\n, \nTechCrunch\n, \nVentureBeat\n)\nAI companies capture nearly half of global venture funding\nGlobal venture funding increased 38 percent year-over-year to $97 billion in the third quarter, with AI companies receiving 46 percent of that total. Foundation model companies raised the three largest venture rounds: Anthropic secured $13 billion, xAI raised $5.3 billion, and Mistral AI received $2 billion. Anthropic alone accounted for 29 percent of all global AI venture funding in the quarter. U.S.-based companies dominated overall funding, capturing $60 billion of the global total. Hardware companies raised the second-largest amount at $16.2 billion, followed by healthcare and biotech at $15.8 billion, according to data from Crunchbase. (\nReuters\n)\nSamsung tiny model matches far larger ones on reasoning puzzles\nAlexia Jolicoeur-Martineau, a senior AI researcher at Samsung's Advanced Institute of Technology, introduced the Tiny Recursion Model (TRM), a neural network with just 7 million parameters that matches or exceeds models 10,000 times larger on specific reasoning benchmarks. TRM uses a single two-layer network that recursively refines its predictions, achieving 87.4 percent accuracy on Sudoku-Extreme, 85 percent on Maze-Hard, 45 percent on ARC-AGI-1, and 8 percent on ARC-AGI-2. These results are comparable to those of DeepSeek-R1, Gemini 2.5 Pro, and o3-mini while using less than 0.01 percent of their parameters. The code is available on GitHub under an MIT License. (\narXiv\n, \nVentureBeat\n)\nU.S. authorizes Nvidia to ship 500,000 AI GPUs annually to UAE\nThe U.S. government granted Nvidia an export license to ship advanced AI GPUs to the United Arab Emirates, following a May agreement that allows the UAE to purchase up to 500,000 Nvidia processors annually while committing $1.4 trillion of investment in the U.S. over the next decade. The AI accelerators will be operated by American companies with datacenters in the UAE, not by Abu Dhabi-based AI company G42, though G42 will receive 20 percent of AI processors bound for the UAE in future shipments. The policy shifts away from the Biden administration's restrictions on AI chip exports and establishes bilateral frameworks where allies commit to using U.S.-operated cloud infrastructure. (\nTom’s Hardware\n)\nIBM to integrate Claude models into its enterprise software\nIBM will embed Anthropic’s Claude large language models into its software, starting with its integrated development environment for select customers. The partnership also produced a guide for enterprises on building, deploying, and maintaining AI agents, though financial terms remain undisclosed. A recent Menlo Ventures study found enterprises increasingly favor Claude over other AI models, including OpenAI’s, whose usage has declined since 2023. This collaboration underscores Anthropic’s push into the enterprise market, highlighted by its recent deal with Deloitte to deploy Claude to nearly 500,000 employees. (\nTechCrunch\n)\nWant to know more about what matters in AI right now?\nRead \nthe latest issue\n of \nThe Batch\n for in-depth analysis of news and research.\nLast week, Andrew Ng talked about his new course, Agentic AI, which focused on teaching agentic design patterns and best practices for building effective AI agents.\n“Having worked with many teams on many agents, I’ve found that the single biggest predictor of whether someone can build effectively is whether they know how to drive a disciplined process for evals and error analysis. Teams that don’t know how to do this can spend months tweaking agents with little progress to show for it.”\nRead Andrew’s letter \nhere\n.\nOther top AI news and research stories covered in depth:\nAnthropic introduces \nClaude Sonnet 4.5 and Claude Agent SDK\n, offering developers an overhauled Claude Code.\nOpenAI and Meta diversify their offerings with \nnew social video apps\n, as ChatGPT integrates Pulse and Instant Checkout.\nAlibaba expands its AI capabilities with \nthe Qwen3 family\n, featuring a 1 trillion-parameter model, open-weights Qwen3-VL, and Qwen3-Omni voice model.\nText-to-LoRA technology\n enables the generation of task-specific LoRA adapters directly from natural language descriptions.\nSubscribe to Data Points","images":[{"image_id":"figure-ai-unveils-its-third-generation-robot_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/10/The-Batch-ads-and-exclusive-banners--58-.jpg","local_path":null,"alt":"Medical professionals in clinic use copilot screens for patient data analysis, enhancing healthcare decision-making."}]}
{"article_id":"openai-sdk-helps-devs-build-apps-in-chatgpt","title":"OpenAI SDK helps devs build apps in ChatGPT: Zhipu AI’s open competitor to DeepSeek-V3.2 and Sonnet 4","url":"https://www.deeplearning.ai/the-batch/openai-sdk-helps-devs-build-apps-in-chatgpt/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-10-06T12:32:00-07:00","body_text":"In today’s edition of Data Points, you’ll learn more about:\nGoogle’s research preview for CodeMender\nAnthropic’s Petri, an open framework for automating alignment tests\nMusic labels near a deal with AI companies\nNano Banana becoming officially production available\nBut first:\nOpenAI launches apps inside ChatGPT, with new Apps SDK\nAt its DevDay, OpenAI demonstrated a new feature that lets users work with third-party applications directly within ChatGPT conversations. Users can tag apps like Canva (to design posters) or Zillow (to search for homes) while ChatGPT provides context and advice throughout the process. The initial launch includes apps from Booking.com, Canva, Coursera, Expedia, Figma, Spotify, and Zillow, with DoorDash, OpenTable, Target, and Uber coming in the following weeks. Developers can access the new Apps Software Developer Kit in preview today, with app submission for review opening later this year alongside a browsable app directory. CEO Sam Altman says OpenAI plans to share monetization guidance soon. (\nOpenAI\n and \nThe Verge\n)\nZhipu AI releases GLM-4.6 with stronger coding performance\nZhipu AI launched an updated version of its flagship GLM language model that expands the context window from 128,000 to 200,000 tokens and improves coding, reasoning, and agentic capabilities. The model shows gains over its predecessor GLM-4.5 across eight public benchmarks, performing competitively with DeepSeek-V3.2-Exp and Claude Sonnet 4, though it still trails Claude Sonnet 4.5 in coding tasks. In real-world evaluations, GLM-4.6 achieved near parity with Claude Sonnet 4 with a 48.6 percent win rate, while completing tasks with approximately 15 percent fewer tokens than GLM-4.5. The model is available through the Z.ai API platform, works with coding agents like Claude Code, and can be deployed locally using weights published on HuggingFace and ModelScope. (\nZ.ai\n)\nGoogle unveils AI agent to find and patch security flaws in code\nGoogle introduced CodeMender, an AI agent that automatically discovers and fixes security vulnerabilities in software. The system combines Gemini models with program analysis tools like static and dynamic analysis, fuzzing, and SMT solvers to identify security flaws and generate patches. CodeMender uses multi-agent systems and automatic validation to ensure code changes are correct, avoid regressions, and follow style guidelines before human review. The tool already contributed 72 security fixes to open source projects, including codebases with up to 4.5 million lines of code, and can proactively rewrite code to use more secure data structures and APIs. Google is introducing CodeMender as a research preview before making it publicly available. (\nGoogle\n)\nAnthropic releases tool for automated AI safety testing\nAnthropic released Petri, an open source framework that uses AI agents to automatically test frontier models for misaligned behaviors. The tool works by having an auditor agent interact with a target model across different scenarios, simulating environments and creating synthetic tools, while a judge component scores the resulting transcripts for concerning behaviors. When applied to 14 frontier models with 111 seed instructions, Petri elicited behaviors including autonomous deception, oversight subversion, and cooperation with harmful requests. In pilot evaluations, Claude Sonnet 4.5 and GPT-5 showed the strongest safety profiles, while Gemini 2.5 Pro, Grok-4, and Kimi K2 demonstrated concerning rates of user deception. Petri is available now on GitHub. (\nAnthropic\n)\nBig Music close to AI licensing agreements with Big Tech\nUniversal Music and Warner Music are close to finalizing licensing deals with AI companies, including start-ups like ElevenLabs, Stability AI, Suno, and Udio, as well as tech giants like Google and Spotify, according to a new report by the Financial Times. The labels aim to establish payment structures similar to streaming services, where using a song triggers a micropayment, and they want AI companies to develop attribution technology to identify when their music is used. The talks cover licensing songs for AI-generated tracks and training large language models, with deals potentially coming within weeks. These agreements could set a precedent for how AI companies compensate the music industry, as labels seek to avoid the mistakes of the internet era that nearly destroyed their business in the early 2000s. The deals would potentially include settlements for past use of music, including for Suno and Udio, which the labels sued for copyright infringement in 2024. (\nFinancial Times\n)\nGoogle’s Gemini 2.5 Flash Image becomes generally available\nGoogle released its Gemini 2.5 Flash Image model, aka “Nano Banana,” for general production use. New features include support for 10 different aspect ratios. The model allows developers to blend multiple images, maintain character consistency, perform natural language edits, and leverage Gemini’s knowledge base for image generation and modification. The model costs $0.039 per image and is available through the Gemini API on Google AI Studio and Vertex AI. (\nGoogle\n)\nWant to know more about what matters in AI right now?\nRead \nthe latest issue\n of \nThe Batch\n for in-depth analysis of news and research.\nLast week, Andrew Ng talked about LandingAI's Agentic Document Extraction (ADE) tool, which transformed PDF files into LLM-ready markdown text for use in sectors like healthcare, financial services, and legal, emphasizing the importance of accurate data extraction from complex documents.\n“How can we accurately extract information from large PDF files? Humans don’t just glance at a document and reach a conclusion on that basis. Instead, they iteratively examine different parts of the document to pull out information piece by piece. An agentic workflow can do the same.”\nRead Andrew’s letter \nhere\n. \nOther top AI news and research stories covered in depth:\nGoogle’s AP2 provides developers with \nnew tools to build agentic payments\n, in a bid to transform digital transactions.\nA recent study reveals that \nChatGPT users are now more likely to be young, female, and seeking information\n, highlighting demographic shifts in AI use.\nGambling sites are deploying \nAI tools that predict wins and track bets for sports fans\n, marking a new era in sports betting.\nResearchers have developed a \nnew technique that auto-selects training examples to speed up fine-tuning\n, advancing the efficiency of reinforcement learning.\nSubscribe to Data Points","images":[{"image_id":"openai-sdk-helps-devs-build-apps-in-chatgpt_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/10/Whisk_6306af9e913283b82b44ecdb751bc5ccdr.jpeg","local_path":null,"alt":"Musicians in casual clothes shaking hands with business professionals in suits, symbolizing collaboration and creativity."}]}
{"article_id":"deepseek-3-2-turns-to-experimental-attention","title":"DeepSeek 3.2 turns to experimental attention: AI safety bill SB 53 regulates California’s biggest companies","url":"https://www.deeplearning.ai/the-batch/deepseek-3-2-turns-to-experimental-attention/","primary_topic":"data-points","topic_label":"Data Points","tags":["Data Points"],"published_at":"2025-10-03T11:12:00-07:00","body_text":"In today’s edition of Data Points, you’ll learn more about:\nMira Murati’s Tinker’s simplified approach to fine-tuning\nOpenAI’s new video model and social app\nIBM’s embrace of Mamba for Granite 4.0 models\nPerplexity’s AI browser, now free worldwide\nBut first:\nDeepSeek unveils sparse attention model for cheaper long-context inference\nDeepSeek released V3.2-exp, an experimental model with a new sparse attention system that cuts inference costs for long-context operations by up to 50 percent. The system employs an indexer to prioritize specific excerpts and a token selection system to choose relevant tokens, allowing the model to process long contexts with reduced server loads. The open-weight model is available on Hugging Face with an accompanying academic paper on GitHub, enabling third-party researchers to verify DeepSeek’s performance claims. This development addresses the growing challenge of inference costs, a critical bottleneck as AI applications scale. The model is available under an MIT license, or via API at $0.28/$0.42 per million input/output tokens. (\nDeepSeek\n)\nCalifornia enacts AI safety and transparency law SB 53\nCalifornia Governor Gavin Newsom signed the Transparency in Frontier Artificial Intelligence Act (SB 53), requiring advanced AI companies with annual revenues of at least $500 million to report their safety protocols and disclose any major risks posed by their technologies. The law mandates companies publicize their safety best practices in line with national and international standards, and report safety incidents to the state’s Office of Emergency Services. It also strengthens whistleblower protections for employees who warn about potential dangers. Newsom vetoed a stricter safety bill last year that would have required mandatory safety testing and kill switches after intense industry lobbying against those provisions. Industry response to this compromise bill has been mixed, with some large AI companies and tech leaders endorsing its approach and others rejecting its mandates as an overreach. (\nState of California\n)\nThinking Machines’ first product simplifies fine-tuning\nTinker launched today as a managed API service that lets researchers and developers fine-tune language models without managing distributed training infrastructure. The platform supports various open-weight models from small to large, including massive mixture-of-experts models like Qwen-235B-A22B, with model switching requiring only a single code change. The service, the first from Mira Murati’s closely-watched AI startup Thinking Machines, aims to make it easier to customize existing models, as early users from Princeton, Stanford, Berkeley, and Redwood Research have already demonstrated success in specialized applications ranging from theorem proving to chemistry reasoning. Tinker is currently in private beta with free access to start, with usage-based pricing coming in the following weeks. (\nThinking Machines\n)\nOpenAI launches Sora 2 with mobile video creation and sharing app\nOpenAI released Sora 2, its updated video and audio generation model, along with a new iOS social app that allows users to create, remix, and share AI-generated videos. The model demonstrates significant improvements in physical accuracy, including realistic object physics, synchronized dialogue and sound effects, and the ability to follow complex multi-shot instructions while maintaining consistent world state. A feature called “cameos” enables users to insert themselves or others into AI-generated scenes after a one-time video recording for identity verification. The company compares Sora 2 to GPT-3.5, marking a major leap in capabilities and user engagement from the original Sora model launched in February 2024. Some observers wonder whether the video app is more fun than useful, as OpenAI hunts for another “ChatGPT moment” to boost engagement. The Sora iOS app is initially available free in the U.S. and Canada with high usage limits. ChatGPT Pro users gain access to the higher-quality Sora 2 Pro model on sora.com, with an API release to follow. (\nOpenAI\n)\nIBM releases Granite 4.0 models with hybrid architecture\nThe Granite 4.0 family features a novel hybrid Mamba/transformer architecture that reduces memory requirements by up to 70 percent while maintaining competitive performance. The models combine Mamba-2 layers with transformer blocks in a 9:1 ratio, enabling linear rather than quadratic scaling with sequence length and constant memory usage regardless of context size. So far, Granite 4.0 includes four variants: H-Small (32 billion total parameters/9 billion active), H-Tiny (7 billion total/1 billion active), H-Micro (3 billion dense), and Micro (3 billion conventional transformer). These models can run on significantly cheaper GPUs and handle workloads like long-context RAG systems and multiple concurrent sessions that would overwhelm conventional transformers. The models are available now on IBM’s watsonx.ai, through partners including Hugging Face, NVIDIA NIM, and Ollama, with Amazon SageMaker and Microsoft Azure support coming soon, all under Apache 2.0 licensing. Reasoning versions of all models and a Medium-sized model are expected soon. (\nIBM\n)\nPerplexity launches Comet browser worldwide for free\nPerplexity released its AI-powered web browser Comet globally on Thursday, making it free to all users after initially charging $200 monthly for Perplexity Max subscribers. The browser functions as a personal assistant that can search the web, organize tabs, draft emails, shop, and perform other tasks while millions of users waited on the access list. Perplexity faces competition from Google’s Gemini integration in Chrome, Anthropic’s browser-based AI agent, and OpenAI’s Operator, which all offer similar browser-based AI capabilities. The move to free access could help Perplexity gain market share in the increasingly crowded AI browser space, particularly after the company made an unsolicited $34.5 billion bid for Google’s Chrome browser in August. (\nCNBC\n)\nStill want to know more about what matters in AI right now?\nRead \nthis week’s issue\n of \nThe Batch\n for in-depth analysis of news and research.\nThis week, Andrew Ng talked about LandingAI’s Agentic Document Extraction (ADE) tool, which transforms PDF files into LLM-ready markdown text for use in sectors like healthcare, financial services, and law, emphasizing the upside of AI-based data extraction from complex documents.\n“Before LLMs, many documents sat on individuals’ laptops or in businesses’ cloud storage buckets unexamined, because we did not have software that could make sense of them. But now that LLMs can make sense of text, there’s significant value in getting information out of the numerous PDF documents, forms, and slide decks we’ve stored for processing — if we are able to extract the information in them accurately.”\nRead Andrew’s full letter \nhere\n.\nOther top AI news and research stories we covered in depth:\nOpenAI partners with Oracle, Nvidia, Softbank, and more to \nbuild out 20 gigawatts of data center capacity\n, marking a significant step toward trillion-dollar spending.\nResearchers use genomic language models to \ncreate custom viruses\n, highlighting advancements in AI-generated viral genomes.\nSweden’s STIM has built an ecosystem for \ntraining AI models on copyrighted music\n while ensuring compensation for original artists.\nGoogle’s AlphaEarth Foundations \ntracks the whole planet’s climate, land use, and potential for disasters\n in detail and at scale, modeling Earth in 10-meter squares.\nSubscribe to Data Points","images":[{"image_id":"deepseek-3-2-turns-to-experimental-attention_hero","url":"https://charonhub.deeplearning.ai/content/images/2025/10/The-Batch-ads-and-exclusive-banners---2025-10-03T123529.432.png","local_path":null,"alt":"A person at a desk watches a fantasy landscape with waterfalls and flying creature on a computer screen."}]}
